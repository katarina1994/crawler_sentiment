Po prvi puta i to nakon intenzivnog pritiska javnosti, Facebook je objavio svoje interne podatke o kolièini i prirodi nasilnog sadržaja koji moderatori uklanjaju s te društvene mreže, piše BBC. Podaci su zastrašujuæi: kolièina nasilnog sadržaja dramatièno se poveæala, a govor mržnje uspijeva se probiti kroz pukotine u sistemu. No ipak, èini se da se smanjuje kolièina teroristièke propagande. U izvještaju nedostaju kljuène informacije poput podatka koliko èesto Facebook neki sadržaj ukloni greškom, a ostavi neki koji je trebalo obrisati. Takoðer, izvještaj ne govori ništa o sveukupnoj kolièini nasilnog sadržaja koji je objavljen na toj mreži i to iz jednog vrlo prozaiènog razloga: Facebook to jednostavno ne zna. Umjesto toga, nudi tek procjenu baziranu na analizi nasumièno odabranih objava. 'Postoje razni sitni problemi vezani uz naèin na koji se broje stvari', kaže produkt menadžer Facebooka, Guy Rosen. 'Što više uèimo i postajemo bolji, tako se popravlja i naša metodologija. Bit æemo vrlo otvoreni o svim promjenama i onome što radimo.' Objavljeni podaci odnose se na tromjeseèna razdoblja zadnjeg dijela 2017. i prvog dijela 2018. godine. Facebook je sadržaj podijelio u nekoliko kategorija: grafièko nasilja, golotinja odraslih i seksualni sadržaj, spam, govor mržnje, lažni raèuni. Kompanija procjenjuje da je tri do èetiri posto svih profila lažno te kaže da su izmeðu sijeènja i ožujka ove godine izbrisali 583 milijuna lažnih raèuna. Brojke pokazuju znaèajan porast grafièkog nasilja – èak 183 posto. Kažu da je tome tako radi nove tehnologije detekcije koju koriste, kao i zbog eskalacije rata u Siriji upravo u tom razdoblju. Tad je uklonjeno 3,4 milijuna objava od èega je 86 posto detektirano Facebookovim automatiziranim sistemom. Taj sistem igra vrlo veliku ulogu u detektiranju seksualnog sadržaja, spama i terorizma. Izmeðu sijeènja i ožujka 2018. uklonjeno je 1,9 objava ekstremistièkog sadržaja. Facebook kaže kako je primijetio èak 99,5 posto takvih objava prije nego su se uspjele proširiti mrežom. Potonje æe naroèito razveseliti amerièku i britansku vladu koje su pozvale Facebook da sprijeèi širenje propagande teroristièkih grupa poput Islamske države. 'Poduzimaju doista prave korake kako bi jasno definirali što spada, a što ne spada u slobodu govora, no pred njima je još velik posao', kaže Brandie Nonnecke s Instituta za tehnološka istraživanja i društvena pitanja na Sveuèilištu Berkeley u Kaliforniji. Složenost posla naroèito dolazi do izražaja kad je pitanju govor mržnje, kategorije koju je mnogo teže detektirati automatskim sistemima. Od 2,5 milijuna objava oznaèenih kao govor mržnje, Facebookov automatski sistem detektirao je tek 38 posto, dok su za ostatak zaslužni moderatori. No èak i kad neka objava stigne do ruku živog moderatora, nije lako odrediti što treba obrisati a što ostaviti pa i sama kompanija priznaje da je tu bilo dosta zabuna. 'Postoje nijanse koje tehnologija još ne može razaznati, pa se tu i dalje oslanjamo na žive moderatore koji donose konaènu odluku o statusu nekog sadržaja', kaže Alex Schultz, šef odjela za analizu podataka. Kako bi to potkrijapio, Schultz je rekao da izrazi za gej osobe koje se koriste u sklopu homofobnog napada znaèe nešto pogrdno, no imaju posve drugo znaèenje kad ih koriste same gej osobe u meðusobnoj komunikaciji. Iz tog bi razloga bilo pogrešno jednostavno obrisati sve objave koje sadrže tu konkretnu rijeè. 'No kako pregledom profila znati da je netko gej? Što se mene tièe, ja s tim nemam problema i jasno sam svima dao do znanja da sam gej. No to ne vrijedi za sve i zato je to vrlo složen problem.' U nastojanju da otkriju što su možda propustili, ekipa iz Facebooka provela je nasumièno uzorkovanje. Uzeli su 10.000 objava i prebrojali koliko se èesto dogaðalo kršenje pravila o govoru mržnje i nasilnom sadržaju. Rezultati su bili zabrinjavajuæi. 27 postova od njih 10.000 sadržavalo je neki oblik grafièkog nasilja. Uzme li se u obzir da Facebook ima milijardu i pol korisnika, to bi znaèilo na desetke milijuna nasilnih objava svakoga dana koje prolaze neopaženo. Istom je tehnikom procijenjeno da devet od 10.000 objava sadrži golotinju ili seksualni sadržaj. Kolièina sadržaja vezanog uz terorizam bila je premala da bi se uzorkovala na ovaj naèin, a što se tièe govora mržnje Schultz kaže kako im nedostaje pouzdanih podataka za takvu procjenu. 'Trenutno ne možemo izmjeriti koliko je govor mržnje prisutan u objavama jer naprosto nismo naše zaposlenike zamolili da provjere sve objave i odluèe je li nešto govor mržnje ili nije. To je jako teško provesti i u tom procesu radimo greške koje ispravljamo u hodu', kaže Schultz. No Dottie Lux, organizatorica evenata iz San Francisca koja upozorava na neuspjeh Facebooka da sprijeèi napade na manjinske grupe ljudi, kaže kako to što je nešto teško izvesti, nije isprika. 'Nemam više razumijevanja za isprike tipa 'Pa to je teško!' jer takve stvari nisu novost. Našli su vremena pustiti u promet aplikaciju za pronalaženje partnera i našli su vremena nakaèiti je na moj bankovni raèun, no ne nalaze vremena shvatiti tko su njihovi korisnici.' Lux, koja se predstavila kao gej židovka s gej židovskim pogledom na stvari, kaže kako je oslanjanje na same korisnike da prijave govor mržnje u samom startu pogrešno jer otvara moguænost zloporabe i ušutkavanja drugih mišljenja. 'Ljudima sa zlim namjerama dajete moguænost da se ponašaju zloèesto.' Facebook ima više od 17.000 moderatora no kompanija je zasad vrlo malo rekla o tome tko su oni. Kazali su da su pokušali uèiniti sve kako bi se incidentima u koje su ukljuèeni amerièki državljani bavili moderatori iz SAD-a, a incidentima u koje su ukljuèeni državljani neke druge zemlje, moderatori iz te zemlje. No unatoè tome, Lux misli kako bi Facebook trebao biti puno otvoreniji vezano uz rad moderatora. 'Ako upošljavaju ljude koji ne postoje u odreðenim društvenim krugovima i razlièitim kulturama, to neæe biti uèinkovito.' Jutarnji list Copyright © HANZA MEDIA d.o.o. Sva prava pridržana. Promo Izdvajamo Najèitanije     .